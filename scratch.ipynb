{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "movies = pd.read_csv('movies.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "# Merge movies and ratings data\n",
    "movie_ratings = pd.merge(ratings, movies, on='movieId')\n",
    "\n",
    "# User-item matrix\n",
    "user_item_matrix = movie_ratings.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "\n",
    "# User-based collaborative filtering\n",
    "def user_based_cf(user_id, item_id):\n",
    "    user_ratings = user_item_matrix.loc[user_id].dropna()\n",
    "    if user_ratings.empty:\n",
    "        return 0\n",
    "    similar_users = user_item_matrix.corrwith(user_ratings, axis=1)\n",
    "    similar_users = similar_users.dropna().sort_values(ascending=False)\n",
    "    if similar_users.empty:\n",
    "        return 0\n",
    "    user_item_matrix_filtered = user_item_matrix.loc[similar_users.index]\n",
    "    weighted_sum = (user_item_matrix_filtered.loc[:, item_id] * similar_users).sum()\n",
    "    sum_of_weights = similar_users.abs().sum()\n",
    "    if sum_of_weights == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return weighted_sum / sum_of_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Movie Recommendations for User 10\n",
      "- Harry Potter and the Prisoner of Azkaban (2004)\n",
      "- North by Northwest (1959)\n",
      "- It's a Wonderful Life (1946)\n",
      "- Lawrence of Arabia (1962)\n",
      "- 12 Angry Men (1957)\n",
      "- Cinema Paradiso (Nuovo cinema Paradiso) (1989)\n",
      "- Dogville (2003)\n",
      "- Legend of Drunken Master, The (Jui kuen II) (1994)\n",
      "- Doctor Zhivago (1965)\n",
      "- Dead Poets Society (1989)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "user_id = 1\n",
    "item_id = 1# Import libraries\n",
    "import pandas as pd\n",
    "from surprise import Reader, Dataset, SVD\n",
    "\n",
    "# Load data from CSV files\n",
    "movies_df = pd.read_csv(\"movies.csv\")\n",
    "ratings_df = pd.read_csv(\"ratings.csv\")\n",
    "\n",
    "\n",
    "# Reader object for Surprise library\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Create a Surprise dataset from the ratings DataFrame\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Train a recommendation model (SVD in this example)\n",
    "algo = SVD()\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Get user ID for recommendations (replace with actual user input)\n",
    "user_id = 10\n",
    "\n",
    "# Get top 10 movie recommendations for the user\n",
    "user_ratings = ratings_df[ratings_df['userId'] == user_id]\n",
    "recommended_movies = [algo.predict(user_id, movieId) for movieId in movies_df['movieId'] \n",
    "                      if movieId not in user_ratings['movieId'].tolist()]\n",
    "\n",
    "recommended_movies.sort(key=lambda x: x.est, reverse=True)\n",
    "top_10_recommendations = recommended_movies[:10]\n",
    "\n",
    "# Print recommendations\n",
    "print(\"Top 10 Movie Recommendations for User\", user_id)\n",
    "for recommendation in top_10_recommendations:\n",
    "    movie_title = movies_df[movies_df['movieId'] == recommendation.iid]['title'].values[0]\n",
    "    print(f\"- {movie_title}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Content-Based Movie Recommendations for User 10\n",
      "- Sabrina (1995)\n",
      "- Clueless (1995)\n",
      "- Two if by Sea (1996)\n",
      "- French Twist (Gazon maudit) (1995)\n",
      "- If Lucy Fell (1996)\n",
      "- Boomerang (1992)\n",
      "- Pie in the Sky (1996)\n",
      "- Mallrats (1995)\n",
      "- Nine Months (1995)\n",
      "- Forget Paris (1995)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Load data from CSV files\n",
    "movies_df = pd.read_csv(\"movies.csv\")\n",
    "ratings_df = pd.read_csv(\"ratings.csv\")\n",
    "\n",
    "# Merge movie genres into a single string\n",
    "movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "movies_df['genres'] = movies_df['genres'].apply(lambda x: ' '.join(x.split('|')))\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies_df['genres'])\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get recommendations based on content similarity\n",
    "def get_content_based_recommendations(movie_title, cosine_sim=cosine_sim):\n",
    "    idx = movies_df[movies_df['title'] == movie_title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies_df['title'].iloc[movie_indices]\n",
    "\n",
    "# Get user ID for recommendations (replace with actual user input)\n",
    "user_id = 10\n",
    "\n",
    "# Get top 10 movie recommendations for the user\n",
    "user_ratings = ratings_df[ratings_df['userId'] == user_id]\n",
    "watched_movies = set(user_ratings['movieId'])\n",
    "recommended_movies = []\n",
    "\n",
    "for movie_id in watched_movies:\n",
    "    movie_title = movies_df[movies_df['movieId'] == movie_id]['title'].values[0]\n",
    "    similar_movies = get_content_based_recommendations(movie_title)\n",
    "    recommended_movies.extend(similar_movies)\n",
    "\n",
    "recommended_movies = [movie for movie in recommended_movies if movie not in watched_movies]\n",
    "top_10_recommendations = recommended_movies[:10]\n",
    "\n",
    "# Print recommendations\n",
    "print(\"Top 10 Content-Based Movie Recommendations for User\", user_id)\n",
    "for recommendation in top_10_recommendations:\n",
    "    print(f\"- {recommendation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Similar to Movie with ID: 1\n",
      "-  Antz (1998)\n",
      "-  Toy Story 2 (1999)\n",
      "-  Adventures of Rocky and Bullwinkle, The (2000)\n",
      "-  Emperor's New Groove, The (2000)\n",
      "-  Monsters, Inc. (2001)\n",
      "-  Wild, The (2006)\n",
      "-  Shrek the Third (2007)\n",
      "-  Tale of Despereaux, The (2008)\n",
      "-  Asterix and the Vikings (Astérix et les Vikings) (2006)\n",
      "-  Turbo (2013)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Load data from CSV files\n",
    "movies_df = pd.read_csv(\"movies.csv\")\n",
    "ratings_df = pd.read_csv(\"ratings.csv\")\n",
    "\n",
    "# Merge movie genres into a single string\n",
    "movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "movies_df['genres'] = movies_df['genres'].apply(lambda x: ' '.join(x.split('|')))\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies_df['genres'])\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get recommendations based on content similarity\n",
    "def get_content_based_recommendations(movie_id, cosine_sim=cosine_sim):\n",
    "    idx = movies_df[movies_df['movieId'] == movie_id].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies_df['title'].iloc[movie_indices]\n",
    "\n",
    "# Specify movie ID for which recommendations are needed\n",
    "movie_id = 1\n",
    "\n",
    "# Get similar movies based on content similarity\n",
    "similar_movies = get_content_based_recommendations(movie_id)\n",
    "\n",
    "# Print recommendations\n",
    "print(\"Movies Similar to Movie with ID:\", movie_id)\n",
    "for movie_title in similar_movies:\n",
    "    print(\"- \", movie_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Top 10 Movie Recommendations for User 1:\n",
      "- Shawshank Redemption, The (1994)\n",
      "- Godfather, The (1972)\n",
      "- Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\n",
      "- Godfather: Part II, The (1974)\n",
      "- Lawrence of Arabia (1962)\n",
      "- Streetcar Named Desire, A (1951)\n",
      "- Departed, The (2006)\n",
      "- Three Billboards Outside Ebbing, Missouri (2017)\n",
      "- Secrets & Lies (1996)\n",
      "- Guess Who's Coming to Dinner (1967)\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, KNNBasic, CoClustering, BaselineOnly\n",
    "from surprise import Dataset, Reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from CSV files\n",
    "movies_df = pd.read_csv(\"movies.csv\")\n",
    "ratings_df = pd.read_csv(\"ratings.csv\")\n",
    "\n",
    "# Create Surprise Reader object\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Create Surprise Dataset\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Train-test split\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Initialize models\n",
    "svd = SVD()\n",
    "knn = KNNBasic()\n",
    "baseline = BaselineOnly()\n",
    "co_clustering = CoClustering()\n",
    "\n",
    "# Train models\n",
    "svd.fit(trainset)\n",
    "knn.fit(trainset)\n",
    "baseline.fit(trainset)\n",
    "co_clustering.fit(trainset)\n",
    "\n",
    "# Get the list of movies already watched by User 1\n",
    "user_id = 1\n",
    "watched_movies = set(ratings_df[ratings_df['userId'] == user_id]['movieId'])\n",
    "\n",
    "# Generate recommendations excluding watched movies\n",
    "all_movie_ids = set(movies_df['movieId'])\n",
    "unwatched_movies = list(all_movie_ids - watched_movies)\n",
    "\n",
    "# Predict ratings for unwatched movies using each model\n",
    "predictions = []\n",
    "for model in [svd, knn, baseline, co_clustering]:\n",
    "    model_predictions = [(user_id, movie_id, model.predict(user_id, movie_id).est) for movie_id in unwatched_movies]\n",
    "    predictions.extend(model_predictions)\n",
    "\n",
    "# Aggregate predictions\n",
    "combined_preds = {}\n",
    "for user_id, movie_id, est in predictions:\n",
    "    if movie_id not in combined_preds:\n",
    "        combined_preds[movie_id] = [est]\n",
    "    else:\n",
    "        combined_preds[movie_id].append(est)\n",
    "\n",
    "# Take the average of predictions\n",
    "for movie_id in combined_preds:\n",
    "    combined_preds[movie_id] = np.mean(combined_preds[movie_id])\n",
    "\n",
    "# Sort recommendations by the average estimated rating\n",
    "sorted_recommendations = sorted(combined_preds.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get top 10 recommendations\n",
    "top_10_recommendations = sorted_recommendations[:10]\n",
    "\n",
    "# Print recommendations\n",
    "print(f\"Top 10 Movie Recommendations for User {user_id}:\")\n",
    "for movie_id, _ in top_10_recommendations:\n",
    "    movie_title = movies_df[movies_df['movieId'] == movie_id]['title'].values[0]\n",
    "    print(f\"- {movie_title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies watched by User 1:\n",
      "- Toy Story (1995)\n",
      "- Grumpier Old Men (1995)\n",
      "- Heat (1995)\n",
      "- Seven (a.k.a. Se7en) (1995)\n",
      "- Usual Suspects, The (1995)\n",
      "- From Dusk Till Dawn (1996)\n",
      "- Bottle Rocket (1996)\n",
      "- Braveheart (1995)\n",
      "- Rob Roy (1995)\n",
      "- Canadian Bacon (1995)\n",
      "- Desperado (1995)\n",
      "- Billy Madison (1995)\n",
      "- Clerks (1994)\n",
      "- Dumb & Dumber (Dumb and Dumber) (1994)\n",
      "- Ed Wood (1994)\n",
      "- Star Wars: Episode IV - A New Hope (1977)\n",
      "- Pulp Fiction (1994)\n",
      "- Stargate (1994)\n",
      "- Tommy Boy (1995)\n",
      "- Clear and Present Danger (1994)\n",
      "- Forrest Gump (1994)\n",
      "- Jungle Book, The (1994)\n",
      "- Mask, The (1994)\n",
      "- Blown Away (1994)\n",
      "- Dazed and Confused (1993)\n",
      "- Fugitive, The (1993)\n",
      "- Jurassic Park (1993)\n",
      "- Mrs. Doubtfire (1993)\n",
      "- Schindler's List (1993)\n",
      "- So I Married an Axe Murderer (1993)\n",
      "- Three Musketeers, The (1993)\n",
      "- Tombstone (1993)\n",
      "- Dances with Wolves (1990)\n",
      "- Batman (1989)\n",
      "- Silence of the Lambs, The (1991)\n",
      "- Pinocchio (1940)\n",
      "- Fargo (1996)\n",
      "- Mission: Impossible (1996)\n",
      "- James and the Giant Peach (1996)\n",
      "- Space Jam (1996)\n",
      "- Rock, The (1996)\n",
      "- Twister (1996)\n",
      "- Independence Day (a.k.a. ID4) (1996)\n",
      "- She's the One (1996)\n",
      "- Wizard of Oz, The (1939)\n",
      "- Citizen Kane (1941)\n",
      "- Adventures of Robin Hood, The (1938)\n",
      "- Ghost and Mrs. Muir, The (1947)\n",
      "- Mr. Smith Goes to Washington (1939)\n",
      "- Escape to Witch Mountain (1975)\n",
      "- Winnie the Pooh and the Blustery Day (1968)\n",
      "- Three Caballeros, The (1945)\n",
      "- Sword in the Stone, The (1963)\n",
      "- Dumbo (1941)\n",
      "- Pete's Dragon (1977)\n",
      "- Bedknobs and Broomsticks (1971)\n",
      "- Alice in Wonderland (1951)\n",
      "- That Thing You Do! (1996)\n",
      "- Ghost and the Darkness, The (1996)\n",
      "- Swingers (1996)\n",
      "- Willy Wonka & the Chocolate Factory (1971)\n",
      "- Monty Python's Life of Brian (1979)\n",
      "- Reservoir Dogs (1992)\n",
      "- Platoon (1986)\n",
      "- Basic Instinct (1992)\n",
      "- E.T. the Extra-Terrestrial (1982)\n",
      "- Abyss, The (1989)\n",
      "- Monty Python and the Holy Grail (1975)\n",
      "- Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "- Princess Bride, The (1987)\n",
      "- Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "- Clockwork Orange, A (1971)\n",
      "- Apocalypse Now (1979)\n",
      "- Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "- Goodfellas (1990)\n",
      "- Alien (1979)\n",
      "- Psycho (1960)\n",
      "- Blues Brothers, The (1980)\n",
      "- Full Metal Jacket (1987)\n",
      "- Henry V (1989)\n",
      "- Quiet Man, The (1952)\n",
      "- Terminator, The (1984)\n",
      "- Duck Soup (1933)\n",
      "- Shining, The (1980)\n",
      "- Groundhog Day (1993)\n",
      "- Back to the Future (1985)\n",
      "- Highlander (1986)\n",
      "- Young Frankenstein (1974)\n",
      "- Fantasia (1940)\n",
      "- Indiana Jones and the Last Crusade (1989)\n",
      "- Pink Floyd: The Wall (1982)\n",
      "- Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922)\n",
      "- Batman Returns (1992)\n",
      "- Sneakers (1992)\n",
      "- Last of the Mohicans, The (1992)\n",
      "- McHale's Navy (1997)\n",
      "- Best Men (1997)\n",
      "- Grosse Pointe Blank (1997)\n",
      "- Austin Powers: International Man of Mystery (1997)\n",
      "- Con Air (1997)\n",
      "- Face/Off (1997)\n",
      "- Men in Black (a.k.a. MIB) (1997)\n",
      "- Conan the Barbarian (1982)\n",
      "- L.A. Confidential (1997)\n",
      "- Kiss the Girls (1997)\n",
      "- Game, The (1997)\n",
      "- I Know What You Did Last Summer (1997)\n",
      "- Starship Troopers (1997)\n",
      "- Big Lebowski, The (1998)\n",
      "- Wedding Singer, The (1998)\n",
      "- Welcome to Woop-Woop (1997)\n",
      "- Newton Boys, The (1998)\n",
      "- Wild Things (1998)\n",
      "- Small Soldiers (1998)\n",
      "- All Quiet on the Western Front (1930)\n",
      "- Rocky (1976)\n",
      "- Labyrinth (1986)\n",
      "- Lethal Weapon (1987)\n",
      "- Goonies, The (1985)\n",
      "- Back to the Future Part III (1990)\n",
      "- Bambi (1942)\n",
      "- Saving Private Ryan (1998)\n",
      "- Black Cauldron, The (1985)\n",
      "- Flight of the Navigator (1986)\n",
      "- Great Mouse Detective, The (1986)\n",
      "- Honey, I Shrunk the Kids (1989)\n",
      "- Negotiator, The (1998)\n",
      "- Jungle Book, The (1967)\n",
      "- Rescuers, The (1977)\n",
      "- Return to Oz (1985)\n",
      "- Rocketeer, The (1991)\n",
      "- Sleeping Beauty (1959)\n",
      "- Song of the South (1946)\n",
      "- Tron (1982)\n",
      "- Indiana Jones and the Temple of Doom (1984)\n",
      "- Lord of the Rings, The (1978)\n",
      "- Charlotte's Web (1973)\n",
      "- Secret of NIMH, The (1982)\n",
      "- American Tail, An (1986)\n",
      "- Legend (1985)\n",
      "- NeverEnding Story, The (1984)\n",
      "- Beetlejuice (1988)\n",
      "- Willow (1988)\n",
      "- Toys (1992)\n",
      "- Few Good Men, A (1992)\n",
      "- Rush Hour (1998)\n",
      "- Edward Scissorhands (1990)\n",
      "- American History X (1998)\n",
      "- I Still Know What You Did Last Summer (1998)\n",
      "- Enemy of the State (1998)\n",
      "- King Kong (1933)\n",
      "- Very Bad Things (1998)\n",
      "- Psycho (1998)\n",
      "- Rushmore (1998)\n",
      "- Romancing the Stone (1984)\n",
      "- Young Sherlock Holmes (1985)\n",
      "- Thin Red Line, The (1998)\n",
      "- Howard the Duck (1986)\n",
      "- Texas Chainsaw Massacre, The (1974)\n",
      "- Crocodile Dundee (1986)\n",
      "- ¡Three Amigos! (1986)\n",
      "- 20 Dates (1998)\n",
      "- Office Space (1999)\n",
      "- Logan's Run (1976)\n",
      "- Planet of the Apes (1968)\n",
      "- Lock, Stock & Two Smoking Barrels (1998)\n",
      "- Matrix, The (1999)\n",
      "- Go (1999)\n",
      "- SLC Punk! (1998)\n",
      "- Dick Tracy (1990)\n",
      "- Mummy, The (1999)\n",
      "- Star Wars: Episode I - The Phantom Menace (1999)\n",
      "- Superman (1978)\n",
      "- Superman II (1980)\n",
      "- Dracula (1931)\n",
      "- Frankenstein (1931)\n",
      "- Wolf Man, The (1941)\n",
      "- Rocky Horror Picture Show, The (1975)\n",
      "- Run Lola Run (Lola rennt) (1998)\n",
      "- South Park: Bigger, Longer and Uncut (1999)\n",
      "- Ghostbusters (a.k.a. Ghost Busters) (1984)\n",
      "- Iron Giant, The (1999)\n",
      "- Big (1988)\n",
      "- 13th Warrior, The (1999)\n",
      "- American Beauty (1999)\n",
      "- Excalibur (1981)\n",
      "- Gulliver's Travels (1939)\n",
      "- Total Recall (1990)\n",
      "- Dirty Dozen, The (1967)\n",
      "- Goldfinger (1964)\n",
      "- From Russia with Love (1963)\n",
      "- Dr. No (1962)\n",
      "- Fight Club (1999)\n",
      "- RoboCop (1987)\n",
      "- Who Framed Roger Rabbit? (1988)\n",
      "- Live and Let Die (1973)\n",
      "- Thunderball (1965)\n",
      "- Being John Malkovich (1999)\n",
      "- Spaceballs (1987)\n",
      "- Robin Hood (1973)\n",
      "- Dogma (1999)\n",
      "- Messenger: The Story of Joan of Arc, The (1999)\n",
      "- Longest Day, The (1962)\n",
      "- Green Mile, The (1999)\n",
      "- Easy Rider (1969)\n",
      "- Talented Mr. Ripley, The (1999)\n",
      "- Encino Man (1992)\n",
      "- Sister Act (1992)\n",
      "- Wayne's World (1992)\n",
      "- Scream 3 (2000)\n",
      "- JFK (1991)\n",
      "- Teenage Mutant Ninja Turtles II: The Secret of the Ooze (1991)\n",
      "- Teenage Mutant Ninja Turtles III (1993)\n",
      "- Red Dawn (1984)\n",
      "- Good Morning, Vietnam (1987)\n",
      "- Grumpy Old Men (1993)\n",
      "- Ladyhawke (1985)\n",
      "- Hook (1991)\n",
      "- Predator (1987)\n",
      "- Gladiator (2000)\n",
      "- Road Trip (2000)\n",
      "- Man with the Golden Gun, The (1974)\n",
      "- Blazing Saddles (1974)\n",
      "- Mad Max (1979)\n",
      "- Road Warrior, The (Mad Max 2) (1981)\n",
      "- Shaft (1971)\n",
      "- Big Trouble in Little China (1986)\n",
      "- Shaft (2000)\n",
      "- X-Men (2000)\n",
      "- What About Bob? (1991)\n",
      "- Transformers: The Movie (1986)\n",
      "- M*A*S*H (a.k.a. MASH) (1970)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming ratings_df contains the ratings data\n",
    "# Filter ratings for User 10\n",
    "user_10_ratings = ratings_df[ratings_df['userId'] == 1]\n",
    "\n",
    "# Merge with movies_df to get movie titles\n",
    "movies_watched_by_user_10 = pd.merge(user_10_ratings, movies_df, on='movieId', how='inner')\n",
    "\n",
    "# Print movie titles\n",
    "print(\"Movies watched by User 1:\")\n",
    "for movie_title in movies_watched_by_user_10['title']:\n",
    "    print(\"- \" + movie_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNNBasic...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9561\n",
      "MAE:  0.7325\n",
      "Evaluating SVD...\n",
      "RMSE: 0.8808\n",
      "MAE:  0.6784\n",
      "Evaluating BaselineOnly...\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8785\n",
      "MAE:  0.6778\n",
      "Evaluating CoClustering...\n",
      "RMSE: 0.9468\n",
      "MAE:  0.7331\n",
      "\n",
      "Performance Results:\n",
      "      KNNBasic       SVD  BaselineOnly  CoClustering\n",
      "RMSE  0.956073  0.880797      0.878510      0.946841\n",
      "MAE   0.732520  0.678382      0.677786      0.733073\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import KNNBasic, SVD, BaselineOnly, CoClustering\n",
    "from surprise.accuracy import rmse, mae\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data from CSV files\n",
    "movies_df = pd.read_csv(\"movies.csv\")\n",
    "ratings_df = pd.read_csv(\"ratings.csv\")\n",
    "\n",
    "# Create Surprise Reader object\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Create Surprise Dataset\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Train-test split\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"KNNBasic\": KNNBasic(),\n",
    "    \"SVD\": SVD(),\n",
    "    \"BaselineOnly\": BaselineOnly(),\n",
    "    \"CoClustering\": CoClustering()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    model.fit(trainset)\n",
    "    predictions = model.test(testset)\n",
    "    results[model_name] = {\n",
    "        \"RMSE\": rmse(predictions),\n",
    "        \"MAE\": mae(predictions)\n",
    "    }\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nPerformance Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.9986157839587124\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load data from CSV files\n",
    "movies_df = pd.read_csv(\"movies.csv\")\n",
    "ratings_df = pd.read_csv(\"ratings.csv\")\n",
    "\n",
    "# Merge movie genres into a single string\n",
    "movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "movies_df['genres'] = movies_df['genres'].apply(lambda x: ' '.join(x.split('|')))\n",
    "\n",
    "# Merge ratings with movies\n",
    "data = pd.merge(ratings_df, movies_df, on='movieId')\n",
    "\n",
    "# Feature Engineering\n",
    "X = data[['movieId', 'title', 'genres']]  # Use 'data' instead of 'movies_df'\n",
    "y = data['rating']\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(X['genres'])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict ratings\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoges\\AppData\\Local\\Temp\\ipykernel_9076\\3737711677.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  recommendations = pd.concat([recommendations, pd.DataFrame({'movieId': [movie_id], 'title': [title], 'predicted_rating': [predicted_rating]})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Recommendations for User 1:\n",
      "title                                                         \n",
      "                       Teenage Mutant Ninja Turtles III (1993)\n",
      "                                              Ladyhawke (1985)\n",
      "                                          Wayne's World (1992)\n",
      "                                               Scream 3 (2000)\n",
      "                                                    JFK (1991)\n",
      "Teenage Mutant Ninja Turtles II: The Secret of the Ooze (1991)\n",
      "                                               Red Dawn (1984)\n",
      "                                  Good Morning, Vietnam (1987)\n",
      "                                         Grumpy Old Men (1993)\n",
      "                                                   Hook (1991)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'user_id' column in ratings_df represents user IDs\n",
    "# Let's filter ratings_df to get ratings by user 1\n",
    "user_1_ratings = ratings_df[ratings_df['userId'] == 1]\n",
    "\n",
    "# Let's merge user 1's ratings with movie data to get information about the movies\n",
    "user_1_data = pd.merge(user_1_ratings, movies_df, on='movieId')\n",
    "\n",
    "# Let's filter the movies that user 1 rated highly (you can define a threshold for what's considered highly rated)\n",
    "highly_rated_movies = user_1_data[user_1_data['rating'] >= 4]\n",
    "\n",
    "# Now, let's use these highly rated movies to get recommendations\n",
    "recommendations = pd.DataFrame(columns=['movieId', 'title', 'predicted_rating'])\n",
    "\n",
    "for movie_id, title in zip(highly_rated_movies['movieId'], highly_rated_movies['title']):\n",
    "    # Get the TF-IDF vector for the movie's genres\n",
    "    movie_idx = movies_df[movies_df['movieId'] == movie_id].index[0]\n",
    "    tfidf_vector = X_tfidf[movie_idx]\n",
    "    \n",
    "    # Predict the rating for this movie using the trained model\n",
    "    predicted_rating = rf_regressor.predict(tfidf_vector.reshape(1, -1))[0]\n",
    "    \n",
    "    recommendations = pd.concat([recommendations, pd.DataFrame({'movieId': [movie_id], 'title': [title], 'predicted_rating': [predicted_rating]})], ignore_index=True)\n",
    "\n",
    "# Sort the recommendations by predicted rating in descending order\n",
    "recommendations = recommendations.sort_values(by='predicted_rating', ascending=False)\n",
    "\n",
    "# Get the top 10 recommendations\n",
    "top_10_recommendations = recommendations.head(10)\n",
    "\n",
    "print(\"Top 10 Recommendations for User 1:\")\n",
    "print(top_10_recommendations[['title']].to_string(index=False, justify='left'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor: MSE = 0.9986157839587124\n",
      "Gradient Boosting Regressor: MSE = 1.013223073678727\n",
      "Support Vector Regressor: MSE = 1.0195395514788514\n",
      "Linear Regression: MSE = 1.0317016766436247\n",
      "Ridge Regression: MSE = 1.0316982615903076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# Define a dictionary to store the regressors\n",
    "regressors = {\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge()\n",
    "}\n",
    "\n",
    "# Dictionary to store MSE values for each regressor\n",
    "mse_scores = {}\n",
    "\n",
    "# Iterate over each regressor\n",
    "for name, regressor in regressors.items():\n",
    "    # Train the regressor\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict ratings\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    \n",
    "    # Compute mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Store MSE in dictionary\n",
    "    mse_scores[name] = mse\n",
    "\n",
    "# Print MSE values for each regressor\n",
    "for name, mse in mse_scores.items():\n",
    "    print(f\"{name}: MSE = {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.004356600572567\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load data from CSV files\n",
    "movies_df = pd.read_csv(\"movies.csv\")\n",
    "ratings_df = pd.read_csv(\"ratings.csv\")\n",
    "\n",
    "# Merge movie genres into a single string\n",
    "movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "movies_df['genres'] = movies_df['genres'].apply(lambda x: ' '.join(x.split('|')))\n",
    "\n",
    "# Merge ratings with movies\n",
    "data = pd.merge(ratings_df, movies_df, on='movieId')\n",
    "\n",
    "# Feature Engineering\n",
    "X = data[['movieId', 'title', 'genres']]  # Use 'data' instead of 'movies_df'\n",
    "y = data['rating']\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(X['genres'])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize base regressor models\n",
    "base_regressor_1 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "base_regressor_2 = LinearRegression()\n",
    "base_regressor_3 = GradientBoostingRegressor(random_state=42)\n",
    "base_regressor_4 = SVR()\n",
    "base_regressor_5 = Ridge()\n",
    "\n",
    "# BaggingRegressor\n",
    "bagged_regressor_1 = BaggingRegressor(base_regressor_1, n_estimators=10, random_state=42)\n",
    "bagged_regressor_2 = BaggingRegressor(base_regressor_2, n_estimators=10, random_state=42)\n",
    "bagged_regressor_3 = BaggingRegressor(base_regressor_3, n_estimators=10, random_state=42)\n",
    "bagged_regressor_4 = BaggingRegressor(base_regressor_4, n_estimators=10, random_state=42)\n",
    "bagged_regressor_5 = BaggingRegressor(base_regressor_5, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingRegressors\n",
    "bagged_regressor_1.fit(X_train, y_train)\n",
    "bagged_regressor_2.fit(X_train, y_train)\n",
    "bagged_regressor_3.fit(X_train, y_train)\n",
    "bagged_regressor_4.fit(X_train, y_train)\n",
    "bagged_regressor_5.fit(X_train, y_train)\n",
    "\n",
    "# Predict ratings\n",
    "y_pred_1 = bagged_regressor_1.predict(X_test)\n",
    "y_pred_2 = bagged_regressor_2.predict(X_test)\n",
    "y_pred_3 = bagged_regressor_3.predict(X_test)\n",
    "y_pred_4 = bagged_regressor_4.predict(X_test)\n",
    "y_pred_5 = bagged_regressor_5.predict(X_test)\n",
    "\n",
    "# Average the predictions\n",
    "y_pred_avg = (y_pred_1 + y_pred_2 + y_pred_3 + y_pred_4 + y_pred_5) / 5\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred_avg)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This BaggingRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m tfidf_vector \u001b[38;5;241m=\u001b[39m X_tfidf[movie_idx]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Predict rating using bagged regressor\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m predicted_rating \u001b[38;5;241m=\u001b[39m \u001b[43mbagged_regressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidf_vector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Store prediction in DataFrame\u001b[39;00m\n\u001b[0;32m     23\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m: movie_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: title, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_rating\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_rating}, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\yoges\\miniconda3\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:1214\u001b[0m, in \u001b[0;36mBaggingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict regression target for X.\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m    The predicted regression target of an input sample is computed as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1214\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1217\u001b[0m         X,\n\u001b[0;32m   1218\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1221\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1222\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\yoges\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1461\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This BaggingRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Filter ratings by user 1\n",
    "user_1_ratings = ratings_df[ratings_df['userId'] == 1]\n",
    "\n",
    "# Merge user 1's ratings with movie data\n",
    "user_1_data = pd.merge(user_1_ratings, movies_df, on='movieId')\n",
    "\n",
    "# Filter highly rated movies by user 1\n",
    "highly_rated_movies = user_1_data[user_1_data['rating'] >= 4]\n",
    "\n",
    "# Initialize DataFrame to store predicted ratings\n",
    "predictions = pd.DataFrame(columns=['movieId', 'title', 'predicted_rating'])\n",
    "\n",
    "# Iterate over highly rated movies\n",
    "for movie_id, title in zip(highly_rated_movies['movieId'], highly_rated_movies['title']):\n",
    "    # Get TF-IDF vector for movie genres\n",
    "    movie_idx = movies_df[movies_df['movieId'] == movie_id].index[0]\n",
    "    tfidf_vector = X_tfidf[movie_idx]\n",
    "    \n",
    "    # Predict rating using bagged regressor\n",
    "    predicted_rating = bagged_regressor.predict(tfidf_vector.reshape(1, -1))[0]\n",
    "    \n",
    "    # Store prediction in DataFrame\n",
    "    predictions = predictions.append({'movieId': movie_id, 'title': title, 'predicted_rating': predicted_rating}, ignore_index=True)\n",
    "\n",
    "# Sort predictions by predicted rating\n",
    "predictions = predictions.sort_values(by='predicted_rating', ascending=False)\n",
    "\n",
    "# Print top recommendations for user 1\n",
    "print(\"Top Recommendations for User 1 (Bagged Ensemble Model):\")\n",
    "print(predictions[['title', 'predicted_rating']].head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
