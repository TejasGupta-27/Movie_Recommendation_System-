{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO3HCFEt48jD"
      },
      "source": [
        "# Movie Recommendation and Rating Prediction System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fEprCspB0FI"
      },
      "source": [
        "## User-Based Collaborative Filtering using matrix factorization.\n",
        "\n",
        "User-based collaborative filtering predicts a user's rating for an item by finding similar users and using their ratings for the item. It constructs a user-item matrix from existing ratings, computes user similarities, weighs ratings of similar users, and normalizes the prediction. This method offers personalized recommendations based on the preferences of similar users.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bK5rZP6zZL_n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "movies = pd.read_csv('movies.csv')\n",
        "ratings = pd.read_csv('ratings.csv')\n",
        "\n",
        "# Merge movies and ratings data\n",
        "movie_ratings = pd.merge(ratings, movies, on='movieId')\n",
        "\n",
        "# User-item matrix\n",
        "user_item_matrix = movie_ratings.pivot_table(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "# User-based collaborative filtering\n",
        "def user_based_cf(user_id, item_id):\n",
        "    user_ratings = user_item_matrix.loc[user_id].dropna()\n",
        "    if user_ratings.empty:\n",
        "        return 0\n",
        "    similar_users = user_item_matrix.corrwith(user_ratings, axis=1)\n",
        "    similar_users = similar_users.dropna().sort_values(ascending=False)\n",
        "    if similar_users.empty:\n",
        "        return 0\n",
        "    user_item_matrix_filtered = user_item_matrix.loc[similar_users.index]\n",
        "    weighted_sum = (user_item_matrix_filtered.loc[:, item_id] * similar_users).sum()\n",
        "    sum_of_weights = similar_users.abs().sum()\n",
        "    if sum_of_weights == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return weighted_sum / sum_of_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8KzmJpRcLRY",
        "outputId": "937e77e7-63d2-48ab-d316-a1ff4356d1f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-surprise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c41tTeobEMsn"
      },
      "source": [
        "## Content-Based Movie Recommendation System\n",
        "\n",
        "1. **Data Preparation**: Movies' genres are processed for consistency and completeness.\n",
        "\n",
        "2. **Feature Extraction**: Genres are transformed into numerical vectors using TF-IDF.\n",
        "\n",
        "3. **Similarity Calculation**: Cosine similarity is computed between movie vectors, measuring genre similarity.\n",
        "\n",
        "4. **Recommendation Generation**: For a user, watched movies are used to find similar ones based on content.\n",
        "\n",
        "5. **Presentation**: Top similar movies, not yet watched, are suggested to the user.\n",
        "\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKcf9Fr6ZL_r",
        "outputId": "13be9ac2-1a6f-42d1-a84b-a683e5598275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 Content-Based Movie Recommendations for User 10\n",
            "- Sabrina (1995)\n",
            "- Clueless (1995)\n",
            "- Two if by Sea (1996)\n",
            "- French Twist (Gazon maudit) (1995)\n",
            "- If Lucy Fell (1996)\n",
            "- Boomerang (1992)\n",
            "- Pie in the Sky (1996)\n",
            "- Mallrats (1995)\n",
            "- Nine Months (1995)\n",
            "- Forget Paris (1995)\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# Load data from CSV files\n",
        "movies_df = pd.read_csv(\"movies.csv\")\n",
        "ratings_df = pd.read_csv(\"ratings.csv\")\n",
        "\n",
        "# Merge movie genres into a single string\n",
        "movies_df['genres'] = movies_df['genres'].fillna('')\n",
        "movies_df['genres'] = movies_df['genres'].apply(lambda x: ' '.join(x.split('|')))\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(movies_df['genres'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Function to get recommendations based on content similarity\n",
        "def get_content_based_recommendations(movie_title, cosine_sim=cosine_sim):\n",
        "    idx = movies_df[movies_df['title'] == movie_title].index[0]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return movies_df['title'].iloc[movie_indices]\n",
        "\n",
        "# Get user ID for recommendations (replace with actual user input)\n",
        "user_id = 10\n",
        "\n",
        "# Get top 10 movie recommendations for the user\n",
        "user_ratings = ratings_df[ratings_df['userId'] == user_id]\n",
        "watched_movies = set(user_ratings['movieId'])\n",
        "recommended_movies = []\n",
        "\n",
        "for movie_id in watched_movies:\n",
        "    movie_title = movies_df[movies_df['movieId'] == movie_id]['title'].values[0]\n",
        "    similar_movies = get_content_based_recommendations(movie_title)\n",
        "    recommended_movies.extend(similar_movies)\n",
        "\n",
        "recommended_movies = [movie for movie in recommended_movies if movie not in watched_movies]\n",
        "top_10_recommendations = recommended_movies[:10]\n",
        "\n",
        "# Print recommendations\n",
        "print(\"Top 10 Content-Based Movie Recommendations for User\", user_id)\n",
        "for recommendation in top_10_recommendations:\n",
        "    print(f\"- {recommendation}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozi7_4zBQ8Pu"
      },
      "source": [
        "## Content-Based Movie Recommendations Based on Movie ID\n",
        "\n",
        "1. **Data Loading**: The movie and ratings data are loaded from CSV files.\n",
        "\n",
        "2. **Genres Preprocessing**: Movie genres are merged into a single string and processed for consistency.\n",
        "\n",
        "3. **TF-IDF Vectorization**: The TF-IDF Vectorizer from scikit-learn is used to convert movie genres into numerical vectors.\n",
        "\n",
        "4. **Cosine Similarity Calculation**: Cosine similarity is computed between the TF-IDF vectors of movies, resulting in a similarity matrix.\n",
        "\n",
        "5. **Recommendation Function**: A function is defined to retrieve similar movies based on a given movie ID. It takes the cosine similarity matrix as input and returns a list of similar movie titles.\n",
        "\n",
        "6. **Movie ID Specification**: A specific movie ID is provided for which recommendations are sought.\n",
        "\n",
        "7. **Recommendation Retrieval**: Using the defined function, similar movies are retrieved based on content similarity to the specified movie.\n",
        "\n",
        "8. **Presentation**: The list of similar movies is printed to display the recommendations to the user.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCjI7uKgZL_s",
        "outputId": "1500e2ef-fa45-47cc-d804-b9165388f56f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movies Similar to Movie with ID: 1\n",
            "-  Antz (1998)\n",
            "-  Toy Story 2 (1999)\n",
            "-  Adventures of Rocky and Bullwinkle, The (2000)\n",
            "-  Emperor's New Groove, The (2000)\n",
            "-  Monsters, Inc. (2001)\n",
            "-  Wild, The (2006)\n",
            "-  Shrek the Third (2007)\n",
            "-  Tale of Despereaux, The (2008)\n",
            "-  Asterix and the Vikings (AstÃ©rix et les Vikings) (2006)\n",
            "-  Turbo (2013)\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# Load data from CSV files\n",
        "movies_df = pd.read_csv(\"movies.csv\")\n",
        "ratings_df = pd.read_csv(\"ratings.csv\")\n",
        "\n",
        "# Merge movie genres into a single string\n",
        "movies_df['genres'] = movies_df['genres'].fillna('')\n",
        "movies_df['genres'] = movies_df['genres'].apply(lambda x: ' '.join(x.split('|')))\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(movies_df['genres'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Function to get recommendations based on content similarity\n",
        "def get_content_based_recommendations(movie_id, cosine_sim=cosine_sim):\n",
        "    idx = movies_df[movies_df['movieId'] == movie_id].index[0]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return movies_df['title'].iloc[movie_indices]\n",
        "\n",
        "# Specify movie ID for which recommendations are needed\n",
        "movie_id = 1\n",
        "\n",
        "# Get similar movies based on content similarity\n",
        "similar_movies = get_content_based_recommendations(movie_id)\n",
        "\n",
        "# Print recommendations\n",
        "print(\"Movies Similar to Movie with ID:\", movie_id)\n",
        "for movie_title in similar_movies:\n",
        "    print(\"- \", movie_title)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM1LendQRPpU"
      },
      "source": [
        "## Combined Recommendation from Multiple Models\n",
        "\n",
        "1. **Data Load**: Load ratings and movie data.\n",
        "\n",
        "2. **Surprise Setup**: Configure Surprise library.\n",
        "\n",
        "3. **Model Training**: Train SVD, KNNBasic, BaselineOnly, and CoClustering models.\n",
        "\n",
        "4. **Recommendation Generation**: Predict ratings for unwatched movies.\n",
        "\n",
        "5. **Top Recommendations**: Select top 10 recommendations based on average rating.\n",
        "\n",
        "6. **Display**: Print top 10 movie recommendations for User 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLHKQU4CZL_s",
        "outputId": "9090b0b2-772e-4a36-dfcd-a3ef5947dae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Top 10 Movie Recommendations for User 1:\n",
            "- Shawshank Redemption, The (1994)\n",
            "- Three Billboards Outside Ebbing, Missouri (2017)\n",
            "- Godfather, The (1972)\n",
            "- Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\n",
            "- Lawrence of Arabia (1962)\n",
            "- Secrets & Lies (1996)\n",
            "- Godfather: Part II, The (1974)\n",
            "- Departed, The (2006)\n",
            "- Streetcar Named Desire, A (1951)\n",
            "- Guess Who's Coming to Dinner (1967)\n"
          ]
        }
      ],
      "source": [
        "from surprise import SVD, KNNBasic, CoClustering, BaselineOnly\n",
        "from surprise import Dataset, Reader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data from CSV files\n",
        "movies_df = pd.read_csv(\"movies.csv\")\n",
        "ratings_df = pd.read_csv(\"ratings.csv\")\n",
        "\n",
        "# Create Surprise Reader object\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Create Surprise Dataset\n",
        "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Train-test split\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "# Initialize models\n",
        "svd = SVD()\n",
        "knn = KNNBasic()\n",
        "baseline = BaselineOnly()\n",
        "co_clustering = CoClustering()\n",
        "\n",
        "# Train models\n",
        "svd.fit(trainset)\n",
        "knn.fit(trainset)\n",
        "baseline.fit(trainset)\n",
        "co_clustering.fit(trainset)\n",
        "\n",
        "# Get the list of movies already watched by User 1\n",
        "user_id = 1\n",
        "watched_movies = set(ratings_df[ratings_df['userId'] == user_id]['movieId'])\n",
        "\n",
        "# Generate recommendations excluding watched movies\n",
        "all_movie_ids = set(movies_df['movieId'])\n",
        "unwatched_movies = list(all_movie_ids - watched_movies)\n",
        "\n",
        "# Predict ratings for unwatched movies using each model\n",
        "predictions = []\n",
        "for model in [svd, knn, baseline, co_clustering]:\n",
        "    model_predictions = [(user_id, movie_id, model.predict(user_id, movie_id).est) for movie_id in unwatched_movies]\n",
        "    predictions.extend(model_predictions)\n",
        "\n",
        "# Aggregate predictions\n",
        "combined_preds = {}\n",
        "for user_id, movie_id, est in predictions:\n",
        "    if movie_id not in combined_preds:\n",
        "        combined_preds[movie_id] = [est]\n",
        "    else:\n",
        "        combined_preds[movie_id].append(est)\n",
        "\n",
        "# Take the average of predictions\n",
        "for movie_id in combined_preds:\n",
        "    combined_preds[movie_id] = np.mean(combined_preds[movie_id])\n",
        "\n",
        "# Sort recommendations by the average estimated rating\n",
        "sorted_recommendations = sorted(combined_preds.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Get top 10 recommendations\n",
        "top_10_recommendations = sorted_recommendations[:10]\n",
        "\n",
        "# Print recommendations\n",
        "print(f\"Top 10 Movie Recommendations for User {user_id}:\")\n",
        "for movie_id, _ in top_10_recommendations:\n",
        "    movie_title = movies_df[movies_df['movieId'] == movie_id]['title'].values[0]\n",
        "    print(f\"- {movie_title}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_mPcCinRlae"
      },
      "source": [
        "### Movie Recommendation Model Evaluation\n",
        "\n",
        "1. **Data Load**: Load ratings and movie data from CSV files.\n",
        "\n",
        "2. **Surprise Setup**: Configure Surprise library and create a Reader object.\n",
        "\n",
        "3. **Dataset Creation**: Create a Surprise Dataset from the ratings data.\n",
        "\n",
        "4. **Train-Test Split**: Split the dataset into training and testing sets.\n",
        "\n",
        "5. **Model Definition**: Define four recommendation models: KNNBasic, SVD, BaselineOnly, and CoClustering.\n",
        "\n",
        "6. **Model Training and Evaluation**: Train each model on the training set and evaluate its performance using RMSE and MAE metrics on the test set.\n",
        "\n",
        "7. **Results Presentation**: Display the RMSE and MAE for each model in a DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoKb_BzkZL_t",
        "outputId": "f6b85186-8b9a-4267-fb8d-81879b03be45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating KNNBasic...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9561\n",
            "MAE:  0.7325\n",
            "Evaluating SVD...\n",
            "RMSE: 0.8768\n",
            "MAE:  0.6738\n",
            "Evaluating BaselineOnly...\n",
            "Estimating biases using als...\n",
            "RMSE: 0.8785\n",
            "MAE:  0.6778\n",
            "Evaluating CoClustering...\n",
            "RMSE: 0.9511\n",
            "MAE:  0.7349\n",
            "\n",
            "Performance Results:\n",
            "      KNNBasic       SVD  BaselineOnly  CoClustering\n",
            "RMSE  0.956073  0.876759      0.878510      0.951070\n",
            "MAE   0.732520  0.673789      0.677786      0.734887\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.prediction_algorithms import KNNBasic, SVD, BaselineOnly, CoClustering\n",
        "from surprise.accuracy import rmse, mae\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Load data from CSV files\n",
        "movies_df = pd.read_csv(\"movies.csv\")\n",
        "ratings_df = pd.read_csv(\"ratings.csv\")\n",
        "\n",
        "# Create Surprise Reader object\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Create Surprise Dataset\n",
        "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Train-test split\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"KNNBasic\": KNNBasic(),\n",
        "    \"SVD\": SVD(),\n",
        "    \"BaselineOnly\": BaselineOnly(),\n",
        "    \"CoClustering\": CoClustering()\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "    model.fit(trainset)\n",
        "    predictions = model.test(testset)\n",
        "    results[model_name] = {\n",
        "        \"RMSE\": rmse(predictions),\n",
        "        \"MAE\": mae(predictions)\n",
        "    }\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nPerformance Results:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKU5TbUrCzY5",
        "outputId": "d35f332c-d4af-4c14-81f7-1ebae7da0de8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Model      RMSE       MAE\n",
            "0         KNN CF  1.042864  0.821442\n",
            "1            SVM  1.065239  0.832667\n",
            "2  Decision Tree  1.281258  0.946822\n",
            "3            PCA  1.280799  0.948879\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "ratings = pd.read_csv('ratings.csv')\n",
        "\n",
        "# Train-test split\n",
        "train, test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to calculate RMSE and MAE\n",
        "def evaluate(predictions):\n",
        "    rmse = np.sqrt(mean_squared_error(predictions['rating'], predictions['prediction']))\n",
        "    mae = mean_absolute_error(predictions['rating'], predictions['prediction'])\n",
        "    return rmse, mae\n",
        "\n",
        "# Collaborative Filtering using K-Nearest Neighbors\n",
        "knn_cf = KNeighborsRegressor(n_neighbors=10)\n",
        "knn_cf.fit(train[['userId', 'movieId']], train['rating'])\n",
        "knn_cf_preds = knn_cf.predict(test[['userId', 'movieId']])\n",
        "knn_cf_predictions = pd.DataFrame({'rating': test['rating'], 'prediction': knn_cf_preds})\n",
        "knn_cf_rmse, knn_cf_mae = evaluate(knn_cf_predictions)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "svm_regressor = SVR()\n",
        "svm_regressor.fit(train[['userId', 'movieId']], train['rating'])\n",
        "svm_preds = svm_regressor.predict(test[['userId', 'movieId']])\n",
        "svm_predictions = pd.DataFrame({'rating': test['rating'], 'prediction': svm_preds})\n",
        "svm_rmse, svm_mae = evaluate(svm_predictions)\n",
        "\n",
        "# Decision Tree\n",
        "dt_regressor = DecisionTreeRegressor()\n",
        "dt_regressor.fit(train[['userId', 'movieId']], train['rating'])\n",
        "dt_preds = dt_regressor.predict(test[['userId', 'movieId']])\n",
        "dt_predictions = pd.DataFrame({'rating': test['rating'], 'prediction': dt_preds})\n",
        "dt_rmse, dt_mae = evaluate(dt_predictions)\n",
        "\n",
        "# Principal Component Analysis (PCA)\n",
        "pca = PCA()\n",
        "pca_train = pca.fit_transform(train[['userId', 'movieId']])\n",
        "pca_test = pca.transform(test[['userId', 'movieId']])\n",
        "pca_regressor = DecisionTreeRegressor()\n",
        "pca_regressor.fit(pca_train, train['rating'])\n",
        "pca_preds = pca_regressor.predict(pca_test)\n",
        "pca_predictions = pd.DataFrame({'rating': test['rating'], 'prediction': pca_preds})\n",
        "pca_rmse, pca_mae = evaluate(pca_predictions)\n",
        "\n",
        "# Compare results\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['KNN CF', 'SVM', 'Decision Tree', 'PCA'],\n",
        "    'RMSE': [knn_cf_rmse, svm_rmse, dt_rmse, pca_rmse],\n",
        "    'MAE': [knn_cf_mae, svm_mae, dt_mae, pca_mae]\n",
        "})\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_fRhhRtSPdO"
      },
      "source": [
        "## Movie Rating Prediction with Random Forest Regression\n",
        "\n",
        "1. **Data Load**: Load movie and ratings data from CSV files.\n",
        "\n",
        "2. **Genre Processing**: Merge movie genres into a single string and preprocess.\n",
        "\n",
        "3. **Data Merging**: Combine ratings with movies based on movieId.\n",
        "\n",
        "4. **Feature Engineering**: Extract features for prediction (movieId, title, genres).\n",
        "\n",
        "5. **TF-IDF Vectorization**: Convert movie genres into numerical vectors using TF-IDF.\n",
        "\n",
        "6. **Train-Test Split**: Split the dataset into training and testing sets.\n",
        "\n",
        "7. **Model Training**: Train a Random Forest Regressor with 100 estimators.\n",
        "\n",
        "8. **Prediction**: Predict ratings for the test set.\n",
        "\n",
        "9. **Model Evaluation**: Evaluate the model performance using Mean Squared Error (MSE).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLP2HPi9ZL_t",
        "outputId": "b2ab1ee1-e99c-46e6-a1f7-89d760372d6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 0.9986157839587124\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load data from CSV files\n",
        "movies_df = pd.read_csv(\"movies.csv\")\n",
        "ratings_df = pd.read_csv(\"ratings.csv\")\n",
        "\n",
        "# Merge movie genres into a single string\n",
        "movies_df['genres'] = movies_df['genres'].fillna('')\n",
        "movies_df['genres'] = movies_df['genres'].apply(lambda x: ' '.join(x.split('|')))\n",
        "\n",
        "# Merge ratings with movies\n",
        "data = pd.merge(ratings_df, movies_df, on='movieId')\n",
        "\n",
        "# Feature Engineering\n",
        "X = data[['movieId', 'title', 'genres']]  # Use 'data' instead of 'movies_df'\n",
        "y = data['rating']\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "X_tfidf = tfidf.fit_transform(X['genres'])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict ratings\n",
        "y_pred = rf_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2jkZG9R4EDR"
      },
      "source": [
        "## Top Movie Recommendations for User 1 based on Highly Rated Movies\n",
        "\n",
        "1. **Filtering User Ratings**: Extract ratings given by User 1 from the ratings dataframe.\n",
        "\n",
        "2. **Merging Data**: Merge User 1's ratings with movie data to gather information about the rated movies.\n",
        "\n",
        "3. **Filtering Highly Rated Movies**: Select movies highly rated by User 1, using a threshold (e.g., rating >= 4).\n",
        "\n",
        "4. **Recommendation Generation**: For each highly rated movie, predict the rating using the trained Random Forest Regressor model.\n",
        "\n",
        "5. **Sorting Recommendations**: Sort the recommendations by predicted rating in descending order.\n",
        "\n",
        "6. **Top Recommendations**: Display the top 10 movie recommendations based on predicted ratings for User 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc5bOomrZL_u",
        "outputId": "e3883feb-3e2d-4a31-83b5-1fb3926c902a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 Recommendations for User 1:\n",
            "title                                                         \n",
            "                       Teenage Mutant Ninja Turtles III (1993)\n",
            "                                              Ladyhawke (1985)\n",
            "                                          Wayne's World (1992)\n",
            "                                               Scream 3 (2000)\n",
            "                                                    JFK (1991)\n",
            "Teenage Mutant Ninja Turtles II: The Secret of the Ooze (1991)\n",
            "                                               Red Dawn (1984)\n",
            "                                  Good Morning, Vietnam (1987)\n",
            "                                         Grumpy Old Men (1993)\n",
            "                                                   Hook (1991)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming 'user_id' column in ratings_df represents user IDs\n",
        "# Let's filter ratings_df to get ratings by user 1\n",
        "user_1_ratings = ratings_df[ratings_df['userId'] == 1]\n",
        "\n",
        "# Let's merge user 1's ratings with movie data to get information about the movies\n",
        "user_1_data = pd.merge(user_1_ratings, movies_df, on='movieId')\n",
        "\n",
        "# Let's filter the movies that user 1 rated highly (you can define a threshold for what's considered highly rated)\n",
        "highly_rated_movies = user_1_data[user_1_data['rating'] >= 4]\n",
        "\n",
        "# Now, let's use these highly rated movies to get recommendations\n",
        "recommendations = pd.DataFrame(columns=['movieId', 'title', 'predicted_rating'])\n",
        "\n",
        "for movie_id, title in zip(highly_rated_movies['movieId'], highly_rated_movies['title']):\n",
        "    # Get the TF-IDF vector for the movie's genres\n",
        "    movie_idx = movies_df[movies_df['movieId'] == movie_id].index[0]\n",
        "    tfidf_vector = X_tfidf[movie_idx]\n",
        "\n",
        "    # Predict the rating for this movie using the trained model\n",
        "    predicted_rating = rf_regressor.predict(tfidf_vector.reshape(1, -1))[0]\n",
        "\n",
        "    recommendations = pd.concat([recommendations, pd.DataFrame({'movieId': [movie_id], 'title': [title], 'predicted_rating': [predicted_rating]})], ignore_index=True)\n",
        "\n",
        "# Sort the recommendations by predicted rating in descending order\n",
        "recommendations = recommendations.sort_values(by='predicted_rating', ascending=False)\n",
        "\n",
        "# Get the top 10 recommendations\n",
        "top_10_recommendations = recommendations.head(10)\n",
        "\n",
        "print(\"Top 10 Recommendations for User 1:\")\n",
        "print(top_10_recommendations[['title']].to_string(index=False, justify='left'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlDfMyis37-9"
      },
      "source": [
        "## Comparison of Regression Models for Movie Rating Prediction\n",
        "\n",
        "1. **Regressor Definition**: Five regression models (Random Forest Regressor, Gradient Boosting Regressor, Support Vector Regressor, Linear Regression, Ridge Regression) are initialized.\n",
        "\n",
        "2. **Model Training and Evaluation**: Each regressor is trained on the training data and evaluated using Mean Squared Error (MSE) on the test set.\n",
        "\n",
        "3. **MSE Comparison**: The MSE values for each regressor are computed and compared to assess their performance in predicting movie ratings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdnOvw-XZL_u",
        "outputId": "bcc947f9-872b-493d-a26a-464f72e92328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Regressor: MSE = 0.9986157839587124\n",
            "Gradient Boosting Regressor: MSE = 1.013223073678727\n",
            "Support Vector Regressor: MSE = 1.0195395514788514\n",
            "Linear Regression: MSE = 1.0317016766515907\n",
            "Ridge Regression: MSE = 1.0316982219610418\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "\n",
        "# Define a dictionary to store the regressors\n",
        "regressors = {\n",
        "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42),\n",
        "    \"Support Vector Regressor\": SVR(),\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Ridge Regression\": Ridge()\n",
        "}\n",
        "\n",
        "# Dictionary to store MSE values for each regressor\n",
        "mse_scores = {}\n",
        "\n",
        "# Iterate over each regressor\n",
        "for name, regressor in regressors.items():\n",
        "    # Train the regressor\n",
        "    regressor.fit(X_train, y_train)\n",
        "\n",
        "    # Predict ratings\n",
        "    y_pred = regressor.predict(X_test)\n",
        "\n",
        "    # Compute mean squared error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    # Store MSE in dictionary\n",
        "    mse_scores[name] = mse\n",
        "\n",
        "# Print MSE values for each regressor\n",
        "for name, mse in mse_scores.items():\n",
        "    print(f\"{name}: MSE = {mse}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcJo0nu14J22"
      },
      "source": [
        "## Movie Rating Prediction using Bagging Ensemble with Multiple Base Regressors\n",
        "\n",
        "1. **Data Loading and Preprocessing**: Load movie and ratings data from CSV files. Merge movie genres and ratings.\n",
        "\n",
        "2. **Feature Engineering**: Extract features (movieId, title, genres) for prediction. Vectorize genres using TF-IDF.\n",
        "\n",
        "3. **Train-Test Split**: Split the dataset into training and testing sets.\n",
        "\n",
        "4. **Base Regressor Initialization**: Initialize five base regressor models (Random Forest, Linear Regression, Gradient Boosting, Support Vector, Ridge Regression).\n",
        "\n",
        "5. **BaggingRegressor Initialization**: Initialize BaggingRegressor ensembles with each base regressor, using 10 estimators.\n",
        "\n",
        "6. **Model Training**: Train each BaggingRegressor ensemble on the training data.\n",
        "\n",
        "7. **Prediction**: Predict ratings for the test set using each BaggingRegressor ensemble.\n",
        "\n",
        "8. **Ensemble Prediction**: Average the predictions from all BaggingRegressor ensembles.\n",
        "\n",
        "9. **Model Evaluation**: Evaluate the ensemble model's performance using Mean Squared Error (MSE) on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V59spBz3ZL_u",
        "outputId": "491d794f-83e2-4613-ccc8-135bfa5213d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 1.0043565952101163\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load data from CSV files\n",
        "movies_df = pd.read_csv(\"movies.csv\")\n",
        "ratings_df = pd.read_csv(\"ratings.csv\")\n",
        "\n",
        "# Merge movie genres into a single string\n",
        "movies_df['genres'] = movies_df['genres'].fillna('')\n",
        "movies_df['genres'] = movies_df['genres'].apply(lambda x: ' '.join(x.split('|')))\n",
        "\n",
        "# Merge ratings with movies\n",
        "data = pd.merge(ratings_df, movies_df, on='movieId')\n",
        "\n",
        "# Feature Engineering\n",
        "X = data[['movieId', 'title', 'genres']]  # Use 'data' instead of 'movies_df'\n",
        "y = data['rating']\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "X_tfidf = tfidf.fit_transform(X['genres'])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize base regressor models\n",
        "base_regressor_1 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "base_regressor_2 = LinearRegression()\n",
        "base_regressor_3 = GradientBoostingRegressor(random_state=42)\n",
        "base_regressor_4 = SVR()\n",
        "base_regressor_5 = Ridge()\n",
        "\n",
        "# BaggingRegressor\n",
        "bagged_regressor_1 = BaggingRegressor(base_regressor_1, n_estimators=10, random_state=42)\n",
        "bagged_regressor_2 = BaggingRegressor(base_regressor_2, n_estimators=10, random_state=42)\n",
        "bagged_regressor_3 = BaggingRegressor(base_regressor_3, n_estimators=10, random_state=42)\n",
        "bagged_regressor_4 = BaggingRegressor(base_regressor_4, n_estimators=10, random_state=42)\n",
        "bagged_regressor_5 = BaggingRegressor(base_regressor_5, n_estimators=10, random_state=42)\n",
        "\n",
        "# Train the BaggingRegressors\n",
        "bagged_regressor_1.fit(X_train, y_train)\n",
        "bagged_regressor_2.fit(X_train, y_train)\n",
        "bagged_regressor_3.fit(X_train, y_train)\n",
        "bagged_regressor_4.fit(X_train, y_train)\n",
        "bagged_regressor_5.fit(X_train, y_train)\n",
        "\n",
        "# Predict ratings\n",
        "y_pred_1 = bagged_regressor_1.predict(X_test)\n",
        "y_pred_2 = bagged_regressor_2.predict(X_test)\n",
        "y_pred_3 = bagged_regressor_3.predict(X_test)\n",
        "y_pred_4 = bagged_regressor_4.predict(X_test)\n",
        "y_pred_5 = bagged_regressor_5.predict(X_test)\n",
        "\n",
        "# Average the predictions\n",
        "y_pred_avg = (y_pred_1 + y_pred_2 + y_pred_3 + y_pred_4 + y_pred_5) / 5\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred_avg)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ehWWDoVZL_v",
        "outputId": "c4102aec-72f5-4913-e461-120efb7f1ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Recommendations for User 1 (Bagged Ensemble Model):\n",
            "                                                 title  predicted_rating\n",
            "179  Teenage Mutant Ninja Turtles II: The Secret of...          3.985773\n",
            "177                                    Scream 3 (2000)          3.985773\n",
            "190                             Blazing Saddles (1974)          3.985773\n",
            "189                Man with the Golden Gun, The (1974)          3.985773\n",
            "188                                   Road Trip (2000)          3.985773\n",
            "187                                   Gladiator (2000)          3.985773\n",
            "186                                    Predator (1987)          3.985773\n",
            "185                                        Hook (1991)          3.985773\n",
            "184                                   Ladyhawke (1985)          3.985773\n",
            "183                              Grumpy Old Men (1993)          3.985773\n"
          ]
        }
      ],
      "source": [
        "# Initialize DataFrame to store predicted ratings\n",
        "predictions = pd.DataFrame(columns=['movieId', 'title', 'predicted_rating'])\n",
        "\n",
        "# Iterate over highly rated movies\n",
        "for movie_id, title in zip(highly_rated_movies['movieId'], highly_rated_movies['title']):\n",
        "    # Get TF-IDF vector for movie genres\n",
        "    movie_idx = movies_df[movies_df['movieId'] == movie_id].index[0]\n",
        "    tfidf_vector = X_tfidf[movie_idx]\n",
        "\n",
        "    # Predict rating using bagged regressors\n",
        "    predicted_rating_ensemble = (bagged_regressor_1.predict(tfidf_vector.reshape(1, -1))[0] +\n",
        "                                  bagged_regressor_2.predict(tfidf_vector.reshape(1, -1))[0] +\n",
        "                                  bagged_regressor_3.predict(tfidf_vector.reshape(1, -1))[0] +\n",
        "                                  bagged_regressor_4.predict(tfidf_vector.reshape(1, -1))[0] +\n",
        "                                  bagged_regressor_5.predict(tfidf_vector.reshape(1, -1))[0]) / 5\n",
        "\n",
        "    # Append prediction to DataFrame\n",
        "    predictions = pd.concat([predictions, pd.DataFrame({'movieId': [movie_id], 'title': [title], 'predicted_rating': [predicted_rating_ensemble]})], ignore_index=True)\n",
        "\n",
        "# Sort predictions by predicted rating\n",
        "predictions = predictions.sort_values(by='predicted_rating', ascending=False)\n",
        "\n",
        "# Print top recommendations for user 1\n",
        "print(\"Top Recommendations for User 1 (Bagged Ensemble Model):\")\n",
        "print(predictions[['title', 'predicted_rating']].head(10))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_i5oeTUi3Xro",
        "YUK9weob3kBi",
        "N4Ff6lz73tL_",
        "B2jkZG9R4EDR",
        "GlDfMyis37-9",
        "fcJo0nu14J22"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
